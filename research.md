---
layout: page
title: Research
permalink: /research/
---

# Research Group CVAR UPM

The research group “Computer Vision & Aerial Robotics Group” at Universidad Politécnica de Madrid (UPM). is focused on increasing the autonomy of the UAV by using vision as the key sensor and being able to autonomously recognise its environment. This main feature allows UAVs to be able to safety manoeuvre in both outdoors and indoors for interacting with the environment and taking data out of it in multiple civil applications.

This propose is achieved by CVAR-UPM by researching and being at the forefront of the technology in Image Processing, Control and Artificial Intelligence, whose results are visible through a significant amount of technology transfer projects, international collaboration and scientific publications in most relevant journals and congress in the area. 

Much of the research of the Group is included in its open source UAV framework Aerostack, that is aimed to be spread among the scientific community as well as among the potential developers of UAV developers and that is currently in its second version. The Group has also been awarded in several of the most prestigious international competitions in UAV. 

<a href="https://github.com/cvar-upm/cvar-upm.github.io/blob/main/assets/photoObservingDrone.png">
       <img src="https://github.com/cvar-upm/cvar-upm.github.io/blob/main/assets/photoObservingDrone.png" width=600>
   </a>

The main research areas of activities of the Group are the following:

- Visual detection and recognition in still images using Machine Learning (e.g. Deep Learning)

- Object tracking from UAV, using visual features as well as whole templates

- Image stabilization and mosaicking, that allows to have a large stabilized picture of all the area seen from the UAV

-	On-board pose estimation, using different technologies accordingly to the application, such as homography from motion, 3D marker tracking, stereo vision or omnidirectional vision.

-	Visual 3D map reconstruction of the surrounding environment.

- Sensor fusion of vision with other sensors (e.g. LIDAR, GPS, IMU, ultrasonic)

- Visual control, both in the image plane and in the 3D space, using classical control techniques (PID, LQG, advanced control), as well as relevant modern techniques (e.g. L1, Geometric control, DMC) and the promising Reinforming Learning for both trajectory planning an trajectory control.

- Sensor fusion, including visual information with odometric and GPS information by an EKF which takes into account the UAV dynamic model.

